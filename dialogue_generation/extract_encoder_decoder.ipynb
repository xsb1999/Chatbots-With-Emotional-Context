{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "from keras import callbacks\n",
    "import numpy as np\n",
    "import pickle\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.models import Model, load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_inputs (InputLayer)     (None, None, 3125)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_inputs (InputLayer)     (None, None, 3130)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_lstm1 (LSTM)            [(None, None, 256),  3463168     encoder_inputs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder_lstm1 (LSTM)            [(None, None, 256),  3468288     decoder_inputs[0][0]             \n",
      "                                                                 encoder_lstm1[0][1]              \n",
      "                                                                 encoder_lstm1[0][2]              \n",
      "__________________________________________________________________________________________________\n",
      "encoder_lstm2 (LSTM)            [(None, None, 256),  525312      encoder_lstm1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_lstm2 (LSTM)            [(None, None, 256),  525312      decoder_lstm1[0][0]              \n",
      "                                                                 encoder_lstm2[0][1]              \n",
      "                                                                 encoder_lstm2[0][2]              \n",
      "__________________________________________________________________________________________________\n",
      "encoder_lstm3 (LSTM)            [(None, None, 256),  525312      encoder_lstm2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_lstm3 (LSTM)            [(None, None, 256),  525312      decoder_lstm2[0][0]              \n",
      "                                                                 encoder_lstm3[0][1]              \n",
      "                                                                 encoder_lstm3[0][2]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 3125)   803125      decoder_lstm3[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 9,835,829\n",
      "Trainable params: 9,835,829\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = load_model('../models/seq2seq_model_3layers.hdf5')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构造inference的encoder模型（自己构造input，放到使用训练好的模型中进行计算，得到output）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_lstm1 = model.get_layer(\"encoder_lstm1\")\n",
    "encoder_lstm2 = model.get_layer(\"encoder_lstm2\")\n",
    "encoder_lstm3 = model.get_layer(\"encoder_lstm3\")\n",
    "\n",
    "encoder_inputs = Input(shape=(None, 3125), name='encoder_input')\n",
    "\n",
    "encoder_outputs1, state_h1, state_c1 = encoder_lstm1(encoder_inputs)\n",
    "encoder_outputs2, state_h2, state_c2 = encoder_lstm2(encoder_outputs1)\n",
    "encoder_outputs3, state_h3, state_c3 = encoder_lstm3(encoder_outputs2)\n",
    "\n",
    "encoder_states = [state_h1, state_c1, state_h2, state_c2, state_h3, state_c3]\n",
    "encoder_model = Model(encoder_inputs, encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'encoder_lstm1_1/while:4' shape=(None, 256) dtype=float32>,\n",
       " <tf.Tensor 'encoder_lstm1_1/while:5' shape=(None, 256) dtype=float32>,\n",
       " <tf.Tensor 'encoder_lstm2_1/while:4' shape=(None, 256) dtype=float32>,\n",
       " <tf.Tensor 'encoder_lstm2_1/while:5' shape=(None, 256) dtype=float32>,\n",
       " <tf.Tensor 'encoder_lstm3_1/while:4' shape=(None, 256) dtype=float32>,\n",
       " <tf.Tensor 'encoder_lstm3_1/while:5' shape=(None, 256) dtype=float32>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_model.output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构造inference的decoder模型（自己构造input，放到使用训练好的模型中进行计算，得到output）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_lstm1 = model.get_layer(\"decoder_lstm1\")\n",
    "decoder_lstm2 = model.get_layer(\"decoder_lstm2\")\n",
    "decoder_lstm3 = model.get_layer(\"decoder_lstm3\")\n",
    "decoder_dense = model.get_layer(\"dense_1\")\n",
    "\n",
    "decoder_inputs = Input(shape=(None, 3130), name='decoder_input')\n",
    "decoder_state_input_h1 = Input(shape=(256,))\n",
    "decoder_state_input_c1 = Input(shape=(256,))\n",
    "decoder_states_inputs1 = [decoder_state_input_h1, decoder_state_input_c1]\n",
    "\n",
    "decoder_state_input_h2 = Input(shape=(256,))\n",
    "decoder_state_input_c2 = Input(shape=(256,))\n",
    "decoder_states_inputs2 = [decoder_state_input_h2, decoder_state_input_c2]\n",
    "\n",
    "decoder_state_input_h3 = Input(shape=(256,))\n",
    "decoder_state_input_c3 = Input(shape=(256,))\n",
    "decoder_states_inputs3 = [decoder_state_input_h3, decoder_state_input_c3]\n",
    "\n",
    "decoder_outputs1, state_h1, state_c1 = decoder_lstm1(decoder_inputs, initial_state=decoder_states_inputs1)\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm2(decoder_outputs1, initial_state=decoder_states_inputs2)\n",
    "decoder_outputs3, state_h3, state_c3 = decoder_lstm3(decoder_outputs2, initial_state=decoder_states_inputs3)\n",
    "\n",
    "decoder_states = [state_h1, state_c1, state_h2, state_c2, state_h3, state_c3]\n",
    "decoder_outputs = decoder_dense(decoder_outputs3)\n",
    "decoder_states_inputs = decoder_states_inputs1 + decoder_states_inputs2 + decoder_states_inputs3\n",
    "\n",
    "decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'dense_1_1/truediv:0' shape=(None, None, 3125) dtype=float32>,\n",
       " <tf.Tensor 'decoder_lstm1_1/while:4' shape=(None, 256) dtype=float32>,\n",
       " <tf.Tensor 'decoder_lstm1_1/while:5' shape=(None, 256) dtype=float32>,\n",
       " <tf.Tensor 'decoder_lstm2_1/while:4' shape=(None, 256) dtype=float32>,\n",
       " <tf.Tensor 'decoder_lstm2_1/while:5' shape=(None, 256) dtype=float32>,\n",
       " <tf.Tensor 'decoder_lstm3_1/while:4' shape=(None, 256) dtype=float32>,\n",
       " <tf.Tensor 'decoder_lstm3_1/while:5' shape=(None, 256) dtype=float32>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_model.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model.save(\"../models/encoder_model.hdf5\")\n",
    "decoder_model.save(\"../models/decoder_model.hdf5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
