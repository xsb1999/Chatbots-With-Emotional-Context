{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "from keras import callbacks\n",
    "import numpy as np\n",
    "import pickle\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.models import Model, load_model\n",
    "import jieba\n",
    "import re, random, time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load encoder & decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\keras\\engine\\saving.py:341: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "encoder_model = load_model('../models/encoder_model.hdf5')\n",
    "decoder_model = load_model('../models/decoder_model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   (None, None, 3125)        0         \n",
      "_________________________________________________________________\n",
      "encoder_lstm1 (LSTM)         [(None, None, 256), (None 3463168   \n",
      "_________________________________________________________________\n",
      "encoder_lstm2 (LSTM)         [(None, None, 256), (None 525312    \n",
      "_________________________________________________________________\n",
      "encoder_lstm3 (LSTM)         [(None, None, 256), (None 525312    \n",
      "=================================================================\n",
      "Total params: 4,513,792\n",
      "Trainable params: 4,513,792\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "decoder_input (InputLayer)      (None, None, 3130)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_13 (InputLayer)           (None, 256)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_14 (InputLayer)           (None, 256)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_lstm1 (LSTM)            [(None, None, 256),  3468288     decoder_input[0][0]              \n",
      "                                                                 input_13[0][0]                   \n",
      "                                                                 input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_15 (InputLayer)           (None, 256)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_16 (InputLayer)           (None, 256)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_lstm2 (LSTM)            [(None, None, 256),  525312      decoder_lstm1[0][0]              \n",
      "                                                                 input_15[0][0]                   \n",
      "                                                                 input_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_17 (InputLayer)           (None, 256)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_18 (InputLayer)           (None, 256)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_lstm3 (LSTM)            [(None, None, 256),  525312      decoder_lstm2[0][0]              \n",
      "                                                                 input_17[0][0]                   \n",
      "                                                                 input_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 3125)   803125      decoder_lstm3[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 5,322,037\n",
      "Trainable params: 5,322,037\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load word2id, id2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all = pickle.load(open(\"../models/data_word_id_map.pkl\",\"rb\"))\n",
    "id2word, word2id = data_all[4], data_all[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 规范化数据，转小写，去除标点等其他非字母符号\n",
    "def filter_data(s):\n",
    "    re_han = re.compile(\"([a-zA-Z]+)\")\n",
    "    s = s.lower()\n",
    "    blocks = re_han.split(s)\n",
    "    txt = ''\n",
    "    for blk in blocks:\n",
    "        if re_han.match(blk):\n",
    "            txt = txt + blk + ' '\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_hot(label, wordNum):\n",
    "    label_arr = [0] * wordNum\n",
    "    label_arr[label]=1\n",
    "    return label_arr[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expendToOneHot(x, wordNum):\n",
    "    t = np.expand_dims(x, axis=2)\n",
    "    t = t.tolist()\n",
    "    seqLen = x.shape[1]\n",
    "    for i in range(len(t)):\n",
    "        for j in range(seqLen):\n",
    "            print(str(i)+'-'+str(j))\n",
    "            if(t[i][j][0] == 0):\n",
    "                t[i][j:] = [[0] * wordNum] * (seqLen - j)\n",
    "                break\n",
    "            else:\n",
    "                t[i][j] = get_one_hot(t[i][j][0], wordNum)\n",
    "    return np.array(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'encoder_lstm1/while:4' shape=(None, 256) dtype=float32>,\n",
       " <tf.Tensor 'encoder_lstm1/while:5' shape=(None, 256) dtype=float32>,\n",
       " <tf.Tensor 'encoder_lstm2/while:4' shape=(None, 256) dtype=float32>,\n",
       " <tf.Tensor 'encoder_lstm2/while:5' shape=(None, 256) dtype=float32>,\n",
       " <tf.Tensor 'encoder_lstm3/while:4' shape=(None, 256) dtype=float32>,\n",
       " <tf.Tensor 'encoder_lstm3/while:5' shape=(None, 256) dtype=float32>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_model.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(input_seq):\n",
    "    # 将输入序列进行编码\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    \n",
    "    # happy\n",
    "    emotion = [0,0,1,0,0]\n",
    "    \n",
    "    # 生成一个size=1的空序列\n",
    "    target_seq = np.array([0]*3125 + emotion)\n",
    "    target_seq = np.expand_dims(target_seq, axis=0)\n",
    "    target_seq = np.expand_dims(target_seq, axis=0)\n",
    "    \n",
    "    # 将这个空序列的内容设置为开始字符\n",
    "    target_seq[0, 0, word2id['<SOS>']] = 1\n",
    "    \n",
    "    # 进行字符恢复\n",
    "    # 简单起见，假设batch_size = 1\n",
    "    decoded_sentence = ''\n",
    "    \n",
    "    while True:\n",
    "        output_tokens, state_h1, state_c1, state_h2, state_c2, state_h3, state_c3 = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # sample a token\n",
    "        # 去掉最后5个情绪向量\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = id2word[sampled_token_index]\n",
    "\n",
    "        # 退出条件：生成 <EOS> 或者 超过最大序列长度\n",
    "        if sampled_char == '<EOS>' or len(decoded_sentence) > 50 :\n",
    "            break\n",
    "\n",
    "        decoded_sentence += sampled_char + \" \"\n",
    "\n",
    "        # 更新target_seq\n",
    "        x = np.array([0]*3125 + emotion)\n",
    "        target_seq = np.expand_dims(target_seq, axis=0)\n",
    "        target_seq = np.expand_dims(target_seq, axis=0)\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # 更新中间状态\n",
    "        states_value = [state_h1, state_c1, state_h2, state_c2, state_h3, state_c3]\n",
    "        \n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_input = \"hello\"\n",
    "# user_input = 'excuse me are you angry?'\n",
    "# user_input = 'excuse me are you sad?'\n",
    "user_input = filter_data(user_input).split()\n",
    "user_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-0\n"
     ]
    }
   ],
   "source": [
    "input_words = []\n",
    "for i in user_input:\n",
    "    input_words.append(word2id[i])\n",
    "input_words = np.array(input_words)\n",
    "input_words = np.expand_dims(input_words, axis=0)\n",
    "input_words = expendToOneHot(input_words, 3125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'juggle '"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference(input_words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
