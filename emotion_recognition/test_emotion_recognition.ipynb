{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import os, sys\n",
    "from keras.models import Model, load_model\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('../models/emotion_recognition_model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 50, 3125)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 50, 600)           8222400   \n",
      "_________________________________________________________________\n",
      "utter (Bidirectional)        (None, 600)               2162400   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 3005      \n",
      "=================================================================\n",
      "Total params: 10,387,805\n",
      "Trainable params: 10,387,805\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all = pickle.load(open(\"../models/data_word_id_map.pkl\",\"rb\"))\n",
    "train_x, train_y, test_x, test_y, id2word, word2id = data_all[0], data_all[1], data_all[2], data_all[3], data_all[4], data_all[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_test_result(pred_label, test_label):\n",
    "\n",
    "    true_label = []\n",
    "    predicted_label = []\n",
    "\n",
    "    for i in range(pred_label.shape[0]):\n",
    "        true_label.append(np.argmax(test_label[i]))\n",
    "        predicted_label.append(np.argmax(pred_label[i]))\n",
    "    print(\"Confusion Matrix :\")\n",
    "    print(confusion_matrix(true_label, predicted_label))\n",
    "    print(\"Classification Report :\")\n",
    "    print(classification_report(true_label, predicted_label, digits=4))\n",
    "    print('Weighted FScore: \\n ', precision_recall_fscore_support(true_label, predicted_label, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.0802664e-03, 1.3291232e-02, 9.4877529e-01, 1.8122118e-02,\n",
       "        1.1731087e-02],\n",
       "       [8.1682354e-01, 7.3865737e-04, 1.3790668e-03, 6.7953854e-03,\n",
       "        1.7426334e-01],\n",
       "       [1.3248883e-02, 7.8050566e-01, 2.6508944e-02, 7.3509254e-02,\n",
       "        1.0622736e-01],\n",
       "       ...,\n",
       "       [5.4066600e-03, 9.1925013e-01, 1.2093944e-02, 2.6138881e-02,\n",
       "        3.7110463e-02],\n",
       "       [5.6953534e-02, 1.1969742e-02, 1.3387237e-03, 7.5016436e-03,\n",
       "        9.2223632e-01],\n",
       "       [2.5593489e-04, 9.8778665e-01, 2.3875968e-03, 4.5254924e-03,\n",
       "        5.0444412e-03]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test = model.predict(test_x)\n",
    "pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1476, 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### angry- 0,   sad- 1,   happy- 2,   neutral- 3，frustrated- 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train set result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix :\n",
      "[[125   2   3  31  59]\n",
      " [ 10 129  16  43  42]\n",
      " [ 21  17 220  58   8]\n",
      " [ 21  27  40 181  64]\n",
      " [ 35  29  24  74 197]]\n",
      "Classification Report :\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.5896    0.5682    0.5787       220\n",
      "          1     0.6324    0.5375    0.5811       240\n",
      "          2     0.7261    0.6790    0.7018       324\n",
      "          3     0.4677    0.5435    0.5028       333\n",
      "          4     0.5324    0.5487    0.5405       359\n",
      "\n",
      "avg / total     0.5851    0.5772    0.5797      1476\n",
      "\n",
      "Weighted FScore: \n",
      "  (0.5851061253771398, 0.5772357723577236, 0.5796714974045769, None)\n"
     ]
    }
   ],
   "source": [
    "calc_test_result(pred_test, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix :\n",
      "[[ 92   7   8  11 102]\n",
      " [  1 158  19  12  50]\n",
      " [  7  50 230  23  14]\n",
      " [ 10  58  48 132  85]\n",
      " [ 13  49  20  38 239]]\n",
      "Classification Report :\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.7480    0.4182    0.5364       220\n",
      "          1     0.4907    0.6583    0.5623       240\n",
      "          2     0.7077    0.7099    0.7088       324\n",
      "          3     0.6111    0.3964    0.4809       333\n",
      "          4     0.4878    0.6657    0.5630       359\n",
      "\n",
      "avg / total     0.6031    0.5766    0.5724      1476\n",
      "\n",
      "Weighted FScore: \n",
      "  (0.6031254810357016, 0.5765582655826558, 0.5724006538980043, None)\n"
     ]
    }
   ],
   "source": [
    "calc_test_result(pred_test, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test set result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix :\n",
      "[[ 665   13    7   50  148]\n",
      " [   7  675   22   75   65]\n",
      " [  10   24 1148  112   18]\n",
      " [  24   57   56 1148   90]\n",
      " [  85   36   23  160 1186]]\n",
      "Classification Report :\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8407    0.7531    0.7945       883\n",
      "          1     0.8385    0.7998    0.8187       844\n",
      "          2     0.9140    0.8750    0.8941      1312\n",
      "          3     0.7430    0.8349    0.7863      1375\n",
      "          4     0.7870    0.7960    0.7915      1490\n",
      "\n",
      "avg / total     0.8204    0.8167    0.8174      5904\n",
      "\n",
      "Weighted FScore: \n",
      "  (0.8203820560460446, 0.8167344173441734, 0.817408988907042, None)\n"
     ]
    }
   ],
   "source": [
    "pred_train = model.predict(train_x)\n",
    "calc_test_result(pred_train, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix :\n",
      "[[ 394   31   16   30  412]\n",
      " [   0  710   23   31   80]\n",
      " [   2  139 1114   31   26]\n",
      " [   9  195  152  862  157]\n",
      " [  39   95   33  104 1219]]\n",
      "Classification Report :\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8874    0.4462    0.5938       883\n",
      "          1     0.6068    0.8412    0.7051       844\n",
      "          2     0.8326    0.8491    0.8408      1312\n",
      "          3     0.8147    0.6269    0.7086      1375\n",
      "          4     0.6436    0.8181    0.7204      1490\n",
      "\n",
      "avg / total     0.7567    0.7282    0.7233      5904\n",
      "\n",
      "Weighted FScore: \n",
      "  (0.756663594722732, 0.728150406504065, 0.7232840644052699, None)\n"
     ]
    }
   ],
   "source": [
    "pred_train = model.predict(train_x)\n",
    "calc_test_result(pred_train, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## user input inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 去掉一些停用词\n",
    "def filter_sent(sent):\n",
    "    return sent.replace(\"'\", ' ').replace('-', ' ').replace('.', ' ').replace('?', ' ').replace(':', ' ').replace(';', ' ').replace('(', ' ').replace(')', ' ').replace('!', ' ').replace('/', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_indices(data_x, MaxLen):\n",
    "    length = len(data_x)\n",
    "    word_list = []\n",
    "    for word in data_x:\n",
    "        if not word in word2id:\n",
    "            # 遇到词汇表之外的词就把它归为unknown\n",
    "            word_list.append(word2id['<UNK>'])\n",
    "        else:\n",
    "            word_list.append(word2id[word])\n",
    "    return np.array(word_list + [0]*(MaxLen-length))[:MaxLen]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_hot(label, wordNum):\n",
    "    label_arr = [0] * wordNum\n",
    "    label_arr[label]=1\n",
    "    return label_arr[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expendToOneHot(x, wordNum, MaxLen):\n",
    "    t = np.expand_dims(x, axis=2)\n",
    "    t = t.tolist()\n",
    "    for i in range(len(t)):\n",
    "        for j in range(MaxLen):\n",
    "            if(t[i][j][0] == 0):\n",
    "                t[i][j:] = [[0] * wordNum] * (MaxLen - j)\n",
    "                break\n",
    "            else:\n",
    "                t[i][j] = get_one_hot(t[i][j][0], wordNum)\n",
    "    return np.array(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processUserInput(userInputString):\n",
    "    wordNum = len(id2word)\n",
    "    MaxLen = 50\n",
    "    # 转小写\n",
    "    userInputString = userInputString.lower()\n",
    "    # 按空格split成一个元素为word的list\n",
    "    split_list = filter_sent(userInputString).split()\n",
    "    # 将word按照word2id转为id\n",
    "    sentence_word_indices = get_word_indices(split_list, MaxLen)\n",
    "    # 扩展维度到合适的input维度（1×50×2811）\n",
    "    sentence_word_indices = np.expand_dims(sentence_word_indices, axis=0)\n",
    "    final_input = expendToOneHot(sentence_word_indices, wordNum, MaxLen)    \n",
    "    return final_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input a sentence: i feel bad\n",
      "sad\n",
      "Input a sentence: are you sure\n",
      "neutral\n",
      "Input a sentence: you are bad\n",
      "neutral\n",
      "Input a sentence: i hate you\n",
      "angry\n",
      "Input a sentence: i want to sleep\n",
      "frustrated\n",
      "Input a sentence: yeah\n",
      "neutral\n",
      "Input a sentence: go away\n",
      "frustrated\n",
      "Input a sentence: done\n",
      "sad\n",
      "Input a sentence: it's over\n",
      "sad\n",
      "Input a sentence: OK\n",
      "neutral\n",
      "Input a sentence: I can't work out this problem!\n",
      "frustrated\n",
      "Input a sentence: I can't do it!\n",
      "frustrated\n",
      "Input a sentence: what are you talking about?\n",
      "angry\n",
      "Input a sentence: I am excited\n",
      "happy\n",
      "Input a sentence: exit\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    sentence = input(\"Input a sentence: \")\n",
    "    if sentence == 'exit':\n",
    "        break\n",
    "    userInput = processUserInput(sentence)\n",
    "    \n",
    "    res = model.predict(userInput).argmax()\n",
    "    if(res == 0):\n",
    "        res = 'angry'\n",
    "    elif(res == 1):\n",
    "        res = 'sad'\n",
    "    elif(res == 2):\n",
    "        res = 'happy'\n",
    "    elif(res == 3):\n",
    "        res = 'neutral'\n",
    "    elif(res == 4):\n",
    "        res = 'frustrated'\n",
    "\n",
    "    print(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
